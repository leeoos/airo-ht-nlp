{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOtfQXzHgknKW3o+IveoUZU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Homework 2 (15)"],"metadata":{"id":"aEasE5MjQnDH"}},{"cell_type":"markdown","source":["## Imports and drive"],"metadata":{"id":"yfORk-ebRYWc"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rtCYPf9Qbno","executionInfo":{"status":"ok","timestamp":1705156856736,"user_tz":-60,"elapsed":58501,"user":{"displayName":"Leonardo Colosi","userId":"10241973221821838785"}},"outputId":"9e6991a7-1a86-4d12-9745-297c01d3d128"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# Insatll packages\n","!pip install -q wget # to download data\n","!pip install -q spacy\n","!python -m spacy download en_core_web_sm > /dev/null 2>&1\n","!pip -q install gdown==4.6.0"]},{"cell_type":"code","source":["import pandas as pd\n","import gdown\n","from tqdm import tqdm\n","import zipfile\n","import json\n","import time\n","import os\n","import math\n","\n","\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","from nltk.corpus import wordnet as wn\n","from nltk.stem import WordNetLemmatizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7J5AIFb8RZ1v","executionInfo":{"status":"ok","timestamp":1705156859661,"user_tz":-60,"elapsed":2935,"user":{"displayName":"Leonardo Colosi","userId":"10241973221821838785"}},"outputId":"f47bc4f1-653b-4da2-9bc6-28460f317eff"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}]},{"cell_type":"code","source":["# Connect google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"byH93I--TLVY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705156882341,"user_tz":-60,"elapsed":16542,"user":{"displayName":"Leonardo Colosi","userId":"10241973221821838785"}},"outputId":"68d21059-06b5-487f-d2f1-a14f72a4c70d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Basic concepts for commonsense homework - Hot Topics in NLP\n"],"metadata":{"id":"jnvT73PmQ-OK"}},{"cell_type":"code","source":["# Get dataset\n","!gdown 'https://drive.google.com/uc?id=1O6mNo80ZaBx1GdQy3mEmz8YFyvP0IwLz'\n","commonsense = '/content/basic_concepts.csv'\n","print(\"data acquired\")\n","\n","\n","# Read data in csv format via panda\n","dataset = pd.read_csv(commonsense, names=['Words', 'Id', 'POS', 'Synset'])\n","# print(dataset.iloc[:14, :])"],"metadata":{"id":"jC8cJ3a7Qxdc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705156901317,"user_tz":-60,"elapsed":1663,"user":{"displayName":"Leonardo Colosi","userId":"10241973221821838785"}},"outputId":"7b85a7ff-5373-4a6a-f0a2-f22ad6847cdb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1O6mNo80ZaBx1GdQy3mEmz8YFyvP0IwLz\n","To: /content/basic_concepts.csv\n","\r  0% 0.00/54.5k [00:00<?, ?B/s]\r100% 54.5k/54.5k [00:00<00:00, 88.5MB/s]\n","data acquired\n"]}]},{"cell_type":"code","source":["def get_sysnset_id(word, id):\n","  lower_word = word.lower()\n","  synsets = wn.synsets(lower_word, pos=wn.NOUN)\n","  # print(synset)\n","\n","  for synset in synsets:\n","    for lemma in synset.lemmas():\n","      k_list =  lemma.key()\n","      code_id = k_list.split(':')[1]\n","\n","      if code_id == id:\n","        # print(synset)\n","        # print(code_id)\n","        return synset.name()\n","\n","\n","  # if synset : return synset\n","  # else: None\n","  return None\n"],"metadata":{"id":"ZC49nNwsSwms","executionInfo":{"status":"ok","timestamp":1705156906461,"user_tz":-60,"elapsed":248,"user":{"displayName":"Leonardo Colosi","userId":"10241973221821838785"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["get_sysnset_id('Lion', '05')"],"metadata":{"id":"GYYfrukNVRCi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for index, row in dataset.iterrows():\n","  word = row[0]\n","  id = row[0]\n","  synset = get_sysnset_id(row[0], row[1])\n","\n","  if synset: dataset.at[index, 'Synset'] = synset\n","  else : dataset.at[index, 'Synset'] = ''"],"metadata":{"id":"FH0MNgmoi8lh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset.to_csv('output.csv', index=False)"],"metadata":{"id":"l4_uafdLK3Ar"},"execution_count":null,"outputs":[]}]}